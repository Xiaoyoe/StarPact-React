import { create } from 'zustand';
import type { OllamaServiceStatus, OllamaModel } from '@/shared/types/ollama';

// ========== Types ==========
export type ThemeType = 'light' | 'dark' | 'tech-blue' | 'eye-care' | 'midnight-blue' | 'forest-green' | 'coral-orange' | 'lavender-purple' | 'mint-cyan' | 'caramel-brown' | 'sakura-pink' | 'deep-sea-blue' | 'amber-gold';

export interface ModelConfig {
  id: string;
  name: string;
  provider: string;
  type: 'remote' | 'local';
  apiUrl: string;
  apiKey: string;
  model: string;
  maxTokens: number;
  temperature: number;
  topP: number;
  group: string;
  isFavorite: boolean;
  isActive: boolean;
  createdAt: number;
  presets: ModelPreset[];
  stats: ModelStats;
}

export interface ModelPreset {
  id: string;
  name: string;
  temperature: number;
  topP: number;
  maxTokens: number;
}

export interface ModelStats {
  totalCalls: number;
  successCalls: number;
  avgResponseTime: number;
  lastUsed: number | null;
}

export interface ChatMessage {
  id: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: number;
  modelId?: string;
  modelName?: string;
  isStreaming?: boolean;
  isFavorite?: boolean;
}

export interface Conversation {
  id: string;
  title: string;
  messages: ChatMessage[];
  modelId: string;
  createdAt: number;
  updatedAt: number;
  isFavorite: boolean;
}

export interface LogEntry {
  id: string;
  level: 'info' | 'warn' | 'error' | 'debug';
  message: string;
  timestamp: number;
  module: string;
}

// ========== Store ==========
interface AppState {
  // Theme
  theme: ThemeType;
  setTheme: (theme: ThemeType) => void;

  // Navigation
  activePage: 'chat' | 'models' | 'settings' | 'logs' | 'compare' | 'ini-config' | 'gallery' | 'video-player';
  setActivePage: (page: 'chat' | 'models' | 'settings' | 'logs' | 'compare' | 'ini-config' | 'gallery' | 'video-player') => void;

  // Sidebar
  sidebarCollapsed: boolean;
  toggleSidebar: () => void;

  // Models
  models: ModelConfig[];
  activeModelId: string | null;
  addModel: (model: ModelConfig) => void;
  updateModel: (id: string, updates: Partial<ModelConfig>) => void;
  deleteModel: (id: string) => void;
  setActiveModel: (id: string) => void;
  toggleModelFavorite: (id: string) => void;

  // Conversations
  conversations: Conversation[];
  activeConversationId: string | null;
  addConversation: (conv: Conversation) => void;
  updateConversation: (id: string, updates: Partial<Conversation>) => void;
  deleteConversation: (id: string) => void;
  setActiveConversation: (id: string | null) => void;
  addMessage: (conversationId: string, message: ChatMessage) => void;
  updateMessage: (conversationId: string, messageId: string, updates: Partial<ChatMessage>) => void;

  // Logs
  logs: LogEntry[];
  logsPanelOpen: boolean;
  addLog: (log: LogEntry) => void;
  clearLogs: () => void;
  setLogsPanelOpen: (open: boolean) => void;

  // Settings
  fontSize: number;
  setFontSize: (size: number) => void;
  layoutMode: 'compact' | 'comfortable' | 'wide';
  setLayoutMode: (mode: 'compact' | 'comfortable' | 'wide') => void;
  sendOnEnter: boolean;
  setSendOnEnter: (val: boolean) => void;

  // Search
  searchQuery: string;
  setSearchQuery: (query: string) => void;
}

export const generateId = () => Math.random().toString(36).substring(2, 15) + Date.now().toString(36);

// Default models
const defaultModels: ModelConfig[] = [
  {
    id: 'gpt4',
    name: 'GPT-4o',
    provider: 'OpenAI',
    type: 'remote',
    apiUrl: 'https://api.openai.com/v1/chat/completions',
    apiKey: '',
    model: 'gpt-4o',
    maxTokens: 4096,
    temperature: 0.7,
    topP: 1.0,
    group: 'OpenAI',
    isFavorite: true,
    isActive: true,
    createdAt: Date.now(),
    presets: [
      { id: '1', name: 'åˆ›æ„æ¨¡å¼', temperature: 1.0, topP: 0.95, maxTokens: 4096 },
      { id: '2', name: 'ç²¾å‡†æ¨¡å¼', temperature: 0.2, topP: 0.8, maxTokens: 2048 },
      { id: '3', name: 'å‡è¡¡æ¨¡å¼', temperature: 0.7, topP: 1.0, maxTokens: 4096 },
    ],
    stats: { totalCalls: 156, successCalls: 152, avgResponseTime: 1.8, lastUsed: Date.now() - 300000 },
  },
  {
    id: 'gpt35',
    name: 'GPT-3.5 Turbo',
    provider: 'OpenAI',
    type: 'remote',
    apiUrl: 'https://api.openai.com/v1/chat/completions',
    apiKey: '',
    model: 'gpt-3.5-turbo',
    maxTokens: 4096,
    temperature: 0.7,
    topP: 1.0,
    group: 'OpenAI',
    isFavorite: false,
    isActive: true,
    createdAt: Date.now(),
    presets: [
      { id: '1', name: 'åˆ›æ„æ¨¡å¼', temperature: 1.0, topP: 0.95, maxTokens: 4096 },
      { id: '2', name: 'ç²¾å‡†æ¨¡å¼', temperature: 0.3, topP: 0.8, maxTokens: 2048 },
    ],
    stats: { totalCalls: 423, successCalls: 420, avgResponseTime: 0.8, lastUsed: Date.now() - 600000 },
  },
  {
    id: 'claude3',
    name: 'Claude 3.5 Sonnet',
    provider: 'Anthropic',
    type: 'remote',
    apiUrl: 'https://api.anthropic.com/v1/messages',
    apiKey: '',
    model: 'claude-3-5-sonnet-20241022',
    maxTokens: 8192,
    temperature: 0.7,
    topP: 1.0,
    group: 'Anthropic',
    isFavorite: true,
    isActive: true,
    createdAt: Date.now(),
    presets: [
      { id: '1', name: 'åˆ›æ„æ¨¡å¼', temperature: 0.9, topP: 0.95, maxTokens: 8192 },
      { id: '2', name: 'ç²¾å‡†æ¨¡å¼', temperature: 0.2, topP: 0.8, maxTokens: 4096 },
    ],
    stats: { totalCalls: 89, successCalls: 87, avgResponseTime: 2.1, lastUsed: Date.now() - 120000 },
  },
  {
    id: 'qwen',
    name: 'é€šä¹‰åƒé—® Max',
    provider: 'Alibaba',
    type: 'remote',
    apiUrl: 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
    apiKey: '',
    model: 'qwen-max',
    maxTokens: 6144,
    temperature: 0.85,
    topP: 0.8,
    group: 'å›½äº§æ¨¡å‹',
    isFavorite: false,
    isActive: true,
    createdAt: Date.now(),
    presets: [
      { id: '1', name: 'åˆ›æ„æ¨¡å¼', temperature: 1.0, topP: 0.95, maxTokens: 6144 },
    ],
    stats: { totalCalls: 67, successCalls: 65, avgResponseTime: 1.5, lastUsed: Date.now() - 1800000 },
  },
  {
    id: 'llama',
    name: 'LLaMA 3.1 70B',
    provider: 'Meta',
    type: 'local',
    apiUrl: 'http://localhost:11434/api/chat',
    apiKey: '',
    model: 'llama3.1:70b',
    maxTokens: 4096,
    temperature: 0.8,
    topP: 0.9,
    group: 'æœ¬åœ°æ¨¡å‹',
    isFavorite: false,
    isActive: false,
    createdAt: Date.now(),
    presets: [],
    stats: { totalCalls: 34, successCalls: 30, avgResponseTime: 3.2, lastUsed: null },
  },
  {
    id: 'deepseek',
    name: 'DeepSeek V3',
    provider: 'DeepSeek',
    type: 'remote',
    apiUrl: 'https://api.deepseek.com/chat/completions',
    apiKey: '',
    model: 'deepseek-chat',
    maxTokens: 8192,
    temperature: 0.7,
    topP: 1.0,
    group: 'å›½äº§æ¨¡å‹',
    isFavorite: true,
    isActive: true,
    createdAt: Date.now(),
    presets: [
      { id: '1', name: 'ä»£ç æ¨¡å¼', temperature: 0.1, topP: 0.9, maxTokens: 8192 },
      { id: '2', name: 'å¯¹è¯æ¨¡å¼', temperature: 0.7, topP: 1.0, maxTokens: 4096 },
    ],
    stats: { totalCalls: 212, successCalls: 210, avgResponseTime: 1.2, lastUsed: Date.now() - 60000 },
  },
];

// Demo conversations
const demoConversations: Conversation[] = [
  {
    id: 'conv1',
    title: 'å…³äºReactæ€§èƒ½ä¼˜åŒ–çš„è®¨è®º',
    modelId: 'gpt4',
    createdAt: Date.now() - 3600000,
    updatedAt: Date.now() - 3600000,
    isFavorite: true,
    messages: [
      { id: 'm1', role: 'user', content: 'è¯·ä»‹ç»ä¸€ä¸‹ React 18 ä¸­æœ‰å“ªäº›ä¸»è¦çš„æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆï¼Ÿ', timestamp: Date.now() - 3600000 },
      { id: 'm2', role: 'assistant', content: `# React 18 æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

React 18 å¸¦æ¥äº†å¤šé¡¹é‡è¦çš„æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§ï¼Œä»¥ä¸‹æ˜¯ä¸»è¦æ–¹æ¡ˆï¼š

## 1. è‡ªåŠ¨æ‰¹å¤„ç†ï¼ˆAutomatic Batchingï¼‰
React 18 å°†æ‰€æœ‰çŠ¶æ€æ›´æ–°è‡ªåŠ¨æ‰¹å¤„ç†ä¸ºä¸€æ¬¡æ¸²æŸ“ï¼ŒåŒ…æ‹¬ Promiseã€setTimeout å’Œäº‹ä»¶å¤„ç†ä¸­çš„æ›´æ–°ã€‚

\`\`\`tsx
// React 18 è‡ªåŠ¨æ‰¹å¤„ç†
function handleClick() {
  setCount(c => c + 1);  // ä¸ä¼šè§¦å‘é‡æ¸²æŸ“
  setFlag(f => !f);       // ä¸ä¼šè§¦å‘é‡æ¸²æŸ“
  // React åªä¼šåœ¨æœ€åè¿›è¡Œä¸€æ¬¡é‡æ¸²æŸ“
}
\`\`\`

## 2. Transitions API
é€šè¿‡ \`useTransition\` å’Œ \`startTransition\` åŒºåˆ†ç´§æ€¥å’Œéç´§æ€¥æ›´æ–°ï¼š

\`\`\`tsx
import { useTransition } from 'react';

function SearchResults() {
  const [isPending, startTransition] = useTransition();
  
  function handleChange(e) {
    // ç´§æ€¥æ›´æ–°ï¼šè¾“å…¥æ¡†å†…å®¹
    setInputValue(e.target.value);
    
    // éç´§æ€¥æ›´æ–°ï¼šæœç´¢ç»“æœ
    startTransition(() => {
      setSearchQuery(e.target.value);
    });
  }
}
\`\`\`

## 3. useDeferredValue
å»¶è¿Ÿæ›´æ–°éå…³é”® UI éƒ¨åˆ†ï¼š

\`\`\`tsx
const deferredValue = useDeferredValue(searchQuery);
\`\`\`

## 4. Suspense æ”¹è¿›
æ”¯æŒæœåŠ¡ç«¯æ¸²æŸ“çš„ Suspenseï¼Œé…åˆ React.lazy å®ç°æ›´å¥½çš„ä»£ç åˆ†å‰²ã€‚

## 5. å¹¶å‘æ¸²æŸ“ï¼ˆConcurrent Renderingï¼‰
React å¯ä»¥ä¸­æ–­æ¸²æŸ“ä»¥å¤„ç†æ›´é«˜ä¼˜å…ˆçº§çš„æ›´æ–°ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

> **æ€»ç»“**ï¼šåˆç†ä½¿ç”¨è¿™äº›æ–°ç‰¹æ€§ï¼Œå¯ä»¥æ˜¾è‘—æå‡åº”ç”¨çš„å“åº”é€Ÿåº¦å’Œç”¨æˆ·ä½“éªŒã€‚`, timestamp: Date.now() - 3580000, modelName: 'GPT-4o' },
    ],
  },
  {
    id: 'conv2',
    title: 'Python FastAPI é¡¹ç›®ç»“æ„è®¾è®¡',
    modelId: 'claude3',
    createdAt: Date.now() - 7200000,
    updatedAt: Date.now() - 7200000,
    isFavorite: false,
    messages: [
      { id: 'm3', role: 'user', content: 'å¸®æˆ‘è®¾è®¡ä¸€ä¸ª FastAPI åç«¯é¡¹ç›®çš„ç›®å½•ç»“æ„', timestamp: Date.now() - 7200000 },
      { id: 'm4', role: 'assistant', content: `# FastAPI é¡¹ç›®ç›®å½•ç»“æ„è®¾è®¡

ä»¥ä¸‹æ˜¯ä¸€ä¸ªæ¨èçš„ FastAPI é¡¹ç›®ç»“æ„ï¼š

\`\`\`
project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # åº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ dependencies.py       # ä¾èµ–æ³¨å…¥
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py     # è·¯ç”±èšåˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ users.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ items.py
â”‚   â”‚   â”‚   â””â”€â”€ schemas/
â”‚   â”‚   â”‚       â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚       â”œâ”€â”€ users.py
â”‚   â”‚   â”‚       â””â”€â”€ items.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ security.py       # å®‰å…¨ç›¸å…³
â”‚   â”‚   â””â”€â”€ exceptions.py     # å¼‚å¸¸å¤„ç†
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ user.py           # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ user_service.py   # ä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â””â”€â”€ db/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ database.py       # æ•°æ®åº“è¿æ¥
â”‚       â””â”€â”€ migrations/
â”œâ”€â”€ tests/
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ docker-compose.yml
\`\`\`

è¿™ç§ç»“æ„éµå¾ª **å…³æ³¨ç‚¹åˆ†ç¦»** åŸåˆ™ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•ã€‚`, timestamp: Date.now() - 7180000, modelName: 'Claude 3.5 Sonnet' },
    ],
  },
  {
    id: 'conv3',
    title: 'æœºå™¨å­¦ä¹ å…¥é—¨æŒ‡å—',
    modelId: 'deepseek',
    createdAt: Date.now() - 86400000,
    updatedAt: Date.now() - 86400000,
    isFavorite: false,
    messages: [
      { id: 'm5', role: 'user', content: 'ä½œä¸ºä¸€ä¸ªç¼–ç¨‹åˆå­¦è€…ï¼Œå¦‚ä½•ç³»ç»Ÿå­¦ä¹ æœºå™¨å­¦ä¹ ï¼Ÿ', timestamp: Date.now() - 86400000 },
      { id: 'm6', role: 'assistant', content: `# æœºå™¨å­¦ä¹ ç³»ç»Ÿå­¦ä¹ è·¯å¾„

## ğŸ“š ç¬¬ä¸€é˜¶æ®µï¼šæ•°å­¦åŸºç¡€ï¼ˆ2-4å‘¨ï¼‰
- **çº¿æ€§ä»£æ•°**ï¼šçŸ©é˜µè¿ç®—ã€ç‰¹å¾å€¼åˆ†è§£
- **æ¦‚ç‡è®º**ï¼šæ¡ä»¶æ¦‚ç‡ã€è´å¶æ–¯å®šç†
- **å¾®ç§¯åˆ†**ï¼šæ¢¯åº¦ã€åå¯¼æ•°

## ğŸ’» ç¬¬äºŒé˜¶æ®µï¼šç¼–ç¨‹åŸºç¡€ï¼ˆ2-4å‘¨ï¼‰
- Python åŸºç¡€è¯­æ³•
- NumPyã€Pandas æ•°æ®å¤„ç†
- Matplotlib æ•°æ®å¯è§†åŒ–

## ğŸ¤– ç¬¬ä¸‰é˜¶æ®µï¼šç»å…¸ç®—æ³•ï¼ˆ4-6å‘¨ï¼‰
| ç®—æ³• | ç±»å‹ | éš¾åº¦ |
|------|------|------|
| çº¿æ€§å›å½’ | å›å½’ | â­ |
| é€»è¾‘å›å½’ | åˆ†ç±» | â­â­ |
| å†³ç­–æ ‘ | åˆ†ç±»/å›å½’ | â­â­ |
| SVM | åˆ†ç±» | â­â­â­ |
| éšæœºæ£®æ— | é›†æˆ | â­â­â­ |

## ğŸ§  ç¬¬å››é˜¶æ®µï¼šæ·±åº¦å­¦ä¹ ï¼ˆ6-8å‘¨ï¼‰
1. ç¥ç»ç½‘ç»œåŸºç¡€
2. CNNï¼ˆå›¾åƒè¯†åˆ«ï¼‰
3. RNN/LSTMï¼ˆåºåˆ—æ•°æ®ï¼‰
4. Transformerï¼ˆNLPï¼‰

> ğŸ’¡ **å»ºè®®**ï¼šè¾¹å­¦è¾¹åšé¡¹ç›®ï¼Œä» Kaggle å…¥é—¨ç«èµ›å¼€å§‹å®è·µï¼`, timestamp: Date.now() - 86380000, modelName: 'DeepSeek V3' },
    ],
  },
];

export const useStore = create<AppState>((set) => ({
  // Theme
  theme: 'light',
  setTheme: (theme) => {
    document.documentElement.className = theme === 'light' ? '' : `theme-${theme}`;
    set({ theme });
  },

  // Navigation
  activePage: 'chat',
  setActivePage: (page) => set({ activePage: page }),

  // Sidebar
  sidebarCollapsed: false,
  toggleSidebar: () => set((state) => ({ sidebarCollapsed: !state.sidebarCollapsed })),

  // Models
  models: defaultModels,
  activeModelId: 'gpt4',
  addModel: (model) => set((state) => ({ models: [...state.models, model] })),
  updateModel: (id, updates) => set((state) => ({
    models: state.models.map((m) => (m.id === id ? { ...m, ...updates } : m)),
  })),
  deleteModel: (id) => set((state) => ({
    models: state.models.filter((m) => m.id !== id),
    activeModelId: state.activeModelId === id ? (state.models[0]?.id ?? null) : state.activeModelId,
  })),
  setActiveModel: (id) => set({ activeModelId: id }),
  toggleModelFavorite: (id) => set((state) => ({
    models: state.models.map((m) => (m.id === id ? { ...m, isFavorite: !m.isFavorite } : m)),
  })),

  // Conversations
  conversations: demoConversations,
  activeConversationId: 'conv1',
  addConversation: (conv) => set((state) => ({
    conversations: [conv, ...state.conversations],
    activeConversationId: conv.id,
  })),
  updateConversation: (id, updates) => set((state) => ({
    conversations: state.conversations.map((c) => (c.id === id ? { ...c, ...updates } : c)),
  })),
  deleteConversation: (id) => set((state) => ({
    conversations: state.conversations.filter((c) => c.id !== id),
    activeConversationId: state.activeConversationId === id
      ? (state.conversations.filter(c => c.id !== id)[0]?.id ?? null)
      : state.activeConversationId,
  })),
  setActiveConversation: (id) => set({ activeConversationId: id }),
  addMessage: (conversationId, message) => set((state) => ({
    conversations: state.conversations.map((c) =>
      c.id === conversationId
        ? { ...c, messages: [...c.messages, message], updatedAt: Date.now() }
        : c
    ),
  })),
  updateMessage: (conversationId, messageId, updates) => set((state) => ({
    conversations: state.conversations.map((c) =>
      c.id === conversationId
        ? {
            ...c,
            messages: c.messages.map((m) => (m.id === messageId ? { ...m, ...updates } : m)),
          }
        : c
    ),
  })),

  // Logs
  logs: [
    { id: 'l1', level: 'info', message: 'ç³»ç»Ÿå¯åŠ¨æˆåŠŸ', timestamp: Date.now() - 60000, module: 'System' },
    { id: 'l2', level: 'info', message: 'åŠ è½½æ¨¡å‹é…ç½®: 6ä¸ªæ¨¡å‹å·²å°±ç»ª', timestamp: Date.now() - 55000, module: 'ModelManager' },
    { id: 'l3', level: 'info', message: 'åç«¯æœåŠ¡è¿æ¥æˆåŠŸ (localhost:8000)', timestamp: Date.now() - 50000, module: 'Connection' },
    { id: 'l4', level: 'warn', message: 'LLaMA 3.1 70B æœ¬åœ°æ¨¡å‹æœªå¯åŠ¨', timestamp: Date.now() - 45000, module: 'ModelManager' },
    { id: 'l5', level: 'info', message: 'ä¸»é¢˜åŠ è½½: æµ…è‰²ä¸»é¢˜', timestamp: Date.now() - 40000, module: 'Theme' },
    { id: 'l6', level: 'debug', message: 'å¯¹è¯å†å²åŠ è½½å®Œæˆ: 3æ¡è®°å½•', timestamp: Date.now() - 35000, module: 'Storage' },
  ],
  logsPanelOpen: false,
  addLog: (log) => set((state) => ({ logs: [...state.logs, log] })),
  clearLogs: () => set({ logs: [] }),
  setLogsPanelOpen: (open) => set({ logsPanelOpen: open }),

  // Settings
  fontSize: 14,
  setFontSize: (size) => set({ fontSize: size }),
  layoutMode: 'comfortable',
  setLayoutMode: (mode) => set({ layoutMode: mode }),
  sendOnEnter: true,
  setSendOnEnter: (val) => set({ sendOnEnter: val }),

  // Search
  searchQuery: '',
  setSearchQuery: (query) => set({ searchQuery: query }),

  // Ollama
  ollamaModalOpen: false,
  setOllamaModalOpen: (open) => set({ ollamaModalOpen: open }),
  ollamaStatus: null,
  setOllamaStatus: (status) => set({ ollamaStatus: status }),
  ollamaModels: [],
  setOllamaModels: (models) => set({ ollamaModels: models }),
  ollamaLogs: [],
  addOllamaLog: (log) => set((state) => ({
    ollamaLogs: [...state.ollamaLogs, { ...log, timestamp: Date.now() }],
  })),
  setOllamaLogs: (logs) => set({ ollamaLogs: logs }),
}));
